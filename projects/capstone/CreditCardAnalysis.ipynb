{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 16)\n",
    "LARGE_FIGSIZE = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#list present dir\n",
    "%pwd\n",
    "\n",
    "#set pwd to path\n",
    "default_path = '~/github_code/machine-learning/projects/capstone/'\n",
    "default_filename = 'creditcard.csv'\n",
    "\n",
    "%cd '~/github_code/machine-learning/projects/capstone/'\n",
    "\n",
    "#new present dir\n",
    "%pwd\n",
    "\n",
    "#List files in current folder\n",
    "%ls\n",
    "\n",
    "full_filepath = default_path+default_filename\n",
    "\n",
    "print(full_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cc_csv_data = pd.read_csv(full_filepath, index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (cc_csv_data.shape)\n",
    "display(cc_csv_data)\n",
    "display(cc_csv_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60,30))\n",
    "\n",
    "corr = cc_csv_data.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask, 1)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax = sns.heatmap(corr, mask=mask, square=True, annot=True, cmap='RdBu', fmt='+.3f')\n",
    "    plt.xticks(rotation=45, ha='center')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd.scatter_matrix(cc_csv_data, alpha = 0.3, figsize = (14,8), diagonal = 'kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from pandas.tools.plotting import bootstrap_plot\n",
    "#bootstrap_plot(cc_csv_data, size=50, samples=500, color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_dataset = cc_csv_data.filter(['V1','V2','V3','V4','V5','V6','V7', 'Amount'], axis=1)\n",
    "print (small_dataset.shape)\n",
    "pd.scatter_matrix(small_dataset, alpha = 0.3, diagonal = 'kde', figsize=(60,30));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Scale the data using the natural logarithm\n",
    "log_small_dataset = np.log(small_dataset)\n",
    "\n",
    "# Produce a scatter matrix for each pair of newly-transformed features\n",
    "pd.scatter_matrix(log_small_dataset, alpha = 0.3, diagonal = 'kde', figsize=(60,30));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10,3)\n",
    "axes = axes.flatten()\n",
    "fig.set_size_inches(18, 18)\n",
    "fig.suptitle('Distribution of Features')\n",
    "\n",
    "for i, col in enumerate(cc_csv_data.columns):\n",
    "    feature = cc_csv_data[col]\n",
    "    sns.distplot(feature, label=col, ax=axes[i]).set(xlim=(-1000, 20000),)\n",
    "    axes[i].axvline(feature.mean(),linewidth=1)\n",
    "    axes[i].axvline(feature.median(),linewidth=1, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import visuals as vs\n",
    "\n",
    "log_data = np.log(cc_csv_data)\n",
    "\n",
    "pca = PCA(n_components=6)\n",
    "pca.fit(log_data)\n",
    "\n",
    "# TODO: Transform the sample log-data using the PCA fit above\n",
    "pca_samples = pca.transform(log_data)\n",
    "\n",
    "# Generate PCA results plot\n",
    "#pca_results = vs.pca_results(pca_samples, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
